# -*- coding: utf-8 -*-
"""Mlhiring.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qG_eD-wv-YRG5fMYvkREOZ5EkLO7Lp3y
"""

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

from sklearn.preprocessing import MinMaxScaler
scl = MinMaxScaler(feature_range=(200,500))

import pandas as pd
import numpy as np

link = 'https://drive.google.com/open?id=1EUwJ-YzAlzuaAvRJ2cXqyyadbsn_2S66' 
link1 = 'https://drive.google.com/open?id=1SAvSVsbqmVxmNXc1EaLo2VJKp4QTwpai'

#train data link
fluff, id = link.split('=')
print (id) # Verify that you have everything after '='

#test data link
fluff, id1 = link1.split('=')
print (id1) # Verify that you have everything after '='

#train data
downloaded = drive.CreateFile({'id':id}) 
downloaded.GetContentFile('datahack_train.csv')  
data = pd.read_csv('datahack_train.csv')
# Dataset is now stored in a Panda

downloaded = drive.CreateFile({'id':id1}) 
downloaded.GetContentFile('datahack_test.csv')  
data_test = pd.read_csv('datahack_test.csv')

data_test.drop('source',axis=1,inplace=True)

data_test.drop('financial_institution',axis=1,inplace=True)

data_test.drop('origination_date',axis=1,inplace=True)

data_test.drop('loan_purpose',axis=1,inplace=True)

data_test.drop('insurance_percent',axis=1,inplace=True)

data_test.drop('first_payment_date',axis=1,inplace=True)

X_test = data_test.iloc[:,1:9]
Y_test = data_test.loan_id
X_test.shape

data.drop('source',axis=1,inplace=True)

data.drop('financial_institution',axis=1,inplace=True)

data.drop('loan_purpose',axis=1,inplace=True)

data.drop('origination_date',axis=1,inplace=True)

data.drop('first_payment_date',axis=1,inplace=True)

data.drop('insurance_type',axis=1,inplace=True)

m = np.mean(data.insurance_percent)
n = format(m, '.2f')

def g(s):
  if(s==0):
    return(n)
  else:
    return(s)
data['insurance_percent'] = data.insurance_percent.apply(g)

data['unpaid_principal_bal'] = scl.fit_transform(data.unpaid_principal_bal.values.reshape(-1,1))

data.drop('number_of_borrowers',axis=1,inplace=True)

X = data.iloc[:,1:9]
X.shape

Y = data.m13
Y.value_counts()

from imblearn.over_sampling import SMOTE
smt = SMOTE()
X,Y = smt.fit_resample(X,Y)

from sklearn.model_selection import train_test_split as tts

xtrain,xtest,ytrain,ytest=tts(X,Y,test_size=0.4)

from sklearn.ensemble import AdaBoostClassifier

clf = AdaBoostClassifier()

clf.fit(xtrain,ytrain)

clf.score(xtrain,ytrain)

clf.score(xtest,ytest)

pred = clf.predict(xtest)

from sklearn.metrics import confusion_matrix,classification_report,accuracy_score

accuracy_score(ytest,pred)

print(classification_report(ytest,pred))

predicted = clf.predict(X_test)

sub = pd.DataFrame()

sub['loan_id']=data_test['loan_id']
sub['m13']=predicted

pd.DataFrame(sub).to_csv('Mlhiring2.csv',index=False)

from google.colab import files

files.download('Mlhiring2.csv')

